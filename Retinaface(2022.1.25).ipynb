{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d394e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tested on by GitHub(https://github.com/fisakhan/Face_Pose):\n",
    "Ubuntu-18.04\n",
    "numpy-1.17.0 to 1.19.1\n",
    "tensorflow-2.0.0 to 2.3.0\n",
    "opencv-python-4.0.0.21 to 4.4.0.42\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a5b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# RetinaFace face detector\n",
    "detector_model = tf.saved_model.load('./tf_retinaface_mbv2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13bb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_face(frame, bbs, pointss):\n",
    "    # process only one face (center ?)\n",
    "    offsets = [(bbs[:,0]+bbs[:,2])/2-frame.shape[1]/2,\n",
    "               (bbs[:,1]+bbs[:,3])/2-frame.shape[0]/2]\n",
    "    offset_dist = np.sum(np.abs(offsets),0)\n",
    "    index = np.argmin(offset_dist)\n",
    "    bb = bbs[index]\n",
    "    points = pointss[:,index]\n",
    "    return bb, points\n",
    "            \n",
    "def draw_landmarks(frame, bb, points):\n",
    "    # draw rectangle and landmarks on face\n",
    "    cv2.rectangle(frame,(int(bb[0]),int(bb[1])),(int(bb[2]),int(bb[3])),orange,2)\n",
    "    cv2.circle(frame, (int(points[0]), int(points[5])), 2, (255,0,0), 2)# eye\n",
    "    cv2.circle(frame, (int(points[1]), int(points[6])), 2, (255,0,0), 2)\n",
    "    cv2.circle(frame, (int(points[2]), int(points[7])), 2, (255,0,0), 2)# nose\n",
    "    cv2.circle(frame, (int(points[3]), int(points[8])), 2, (255,0,0), 2)# mouth\n",
    "    cv2.circle(frame, (int(points[4]), int(points[9])), 2, (255,0,0), 2)\n",
    "    \n",
    "    w = int(bb[2])-int(bb[0])# width\n",
    "    h = int(bb[3])-int(bb[1])# height\n",
    "    w2h_ratio = w/h# ratio\n",
    "    eye2box_ratio = (points[0]-bb[0]) / (bb[2]-points[1])\n",
    "    \n",
    "    cv2.putText(frame, \"Width (pixels): {}\".format(w), (10,30), font, font_size, red, 1)\n",
    "    cv2.putText(frame, \"Height (pixels): {}\".format(h), (10,40), font, font_size, red, 1)\n",
    "    \n",
    "    if w2h_ratio < 0.7 or w2h_ratio > 0.9:\n",
    "        #cv2.putText(frame, \"width/height: {0:.2f}\".format(w2h_ratio), (10,40), font, font_size, blue, 1)\n",
    "        cv2.putText(frame, \"Narrow Face\", (10,60), font, font_size, red, 1)\n",
    "    if eye2box_ratio > 1.5 or eye2box_ratio < 0.88:\n",
    "        #cv2.putText(frame, \"leye2lbox/reye2rbox: {0:.2f}\".format((points[0]-bb[0]) / (bb[2]-points[1])), (10,70), font, font_size, red, 1)\n",
    "        cv2.putText(frame, \"Acentric Face\", (10,70), font, font_size, red, 1)\n",
    "\n",
    "def find_roll(pts):\n",
    "    return pts[6] - pts[5]\n",
    "\n",
    "def find_yaw(pts):\n",
    "    le2n = pts[2] - pts[0]\n",
    "    re2n = pts[1] - pts[2]\n",
    "    return le2n - re2n\n",
    "\n",
    "def find_pitch(pts):\n",
    "    eye_y = (pts[5] + pts[6]) / 2\n",
    "    mou_y = (pts[8] + pts[9]) / 2\n",
    "    e2n = eye_y - pts[7]\n",
    "    n2m = pts[7] - mou_y\n",
    "    return e2n/n2m\n",
    "\n",
    "def find_pose(points):\n",
    "    X = points[0:5]\n",
    "    Y = points[5:10]\n",
    "\n",
    "    angle = np.arctan((Y[1]-Y[0])/(X[1]-X[0]))/np.pi*180\n",
    "    alpha = np.cos(np.deg2rad(angle))\n",
    "    beta = np.sin(np.deg2rad(angle))\n",
    "    \n",
    "    # rotated points\n",
    "    Xr = np.zeros((5))\n",
    "    Yr = np.zeros((5))\n",
    "    for i in range(5):\n",
    "        Xr[i] = alpha*X[i]+beta*Y[i]+(1-alpha)*X[2]-beta*Y[2]\n",
    "        Yr[i] = -beta*X[i]+alpha*Y[i]+beta*X[2]+(1-alpha)*Y[2]\n",
    "\n",
    "    # average distance between eyes and mouth\n",
    "    dXtot = (Xr[1]-Xr[0]+Xr[4]-Xr[3])/2\n",
    "    dYtot = (Yr[3]-Yr[0]+Yr[4]-Yr[1])/2\n",
    "\n",
    "    # average distance between nose and eyes\n",
    "    dXnose = (Xr[1]-Xr[2]+Xr[4]-Xr[2])/2\n",
    "    dYnose = (Yr[3]-Yr[2]+Yr[4]-Yr[2])/2\n",
    "\n",
    "    # relative rotation 0% is frontal 100% is profile\n",
    "    Xfrontal = np.abs(np.clip(-90+90/0.5*dXnose/dXtot,-90,90))\n",
    "    Yfrontal = np.abs(np.clip(-90+90/0.5*dYnose/dYtot,-90,90))\n",
    "\n",
    "    return Xfrontal, Yfrontal# horizontal and vertical angles\n",
    "\n",
    "def face_detector(image, image_shape_max=640, score_min=None, pixel_min=None, pixel_max=None, Ain_min=None):\n",
    "    image_shape = image.shape[:2]\n",
    "    \n",
    "    # perform image resize for faster detection    \n",
    "    if image_shape_max:\n",
    "        scale_factor = max([1, max(image_shape)/image_shape_max])\n",
    "    else:\n",
    "        scale_factor = 1\n",
    "        \n",
    "    if scale_factor > 1:        \n",
    "        scaled_image = cv2.resize(image, (0, 0), fx=1/scale_factor, fy=1/scale_factor)\n",
    "        bbs_all, points_all = retinaface(scaled_image)\n",
    "        bbs_all[:,:4]*=scale_factor\n",
    "        points_all*=scale_factor\n",
    "    else:\n",
    "        bbs_all, points_all = retinaface(image)\n",
    "    \n",
    "    bbs=bbs_all.copy()\n",
    "    points=points_all.copy()\n",
    "    \n",
    "    # check detection score\n",
    "    if score_min:\n",
    "        mask=np.array(bbs[:,4]>score_min)\n",
    "        bbs=bbs[mask]\n",
    "        points=points[mask]\n",
    "        if len(bbs)==0:\n",
    "            return [],[],[],[]           \n",
    "\n",
    "    # check pixel height\n",
    "    if pixel_min: \n",
    "        pixel=bbs[:,3]-bbs[:,1]\n",
    "        mask=np.array(pixel>pixel_min)\n",
    "        bbs=bbs[mask]\n",
    "        points=points[mask]\n",
    "        if len(bbs)==0:\n",
    "            return [],[],[],[]           \n",
    "\n",
    "    if pixel_max: \n",
    "        pixel=bbs[:,3]-bbs[:,1]\n",
    "        mask=np.array(pixel<pixel_max)\n",
    "        bbs=bbs[mask]\n",
    "        points=points[mask]\n",
    "        if len(bbs)==0:\n",
    "            return [],[],[],[]           \n",
    "\n",
    "    # check face area in bounding box\n",
    "    Ains = []\n",
    "    for bb in bbs:\n",
    "        Win=min(image_shape[1],bb[2])-max(0,bb[0])\n",
    "        Hin=min(image_shape[0],bb[3])-max(0,bb[1])\n",
    "        Abb=(bb[2]-bb[0])*(bb[3]-bb[1])\n",
    "        Ains.append(Win*Hin/Abb*100 if Abb!=0 else 0)\n",
    "    Ains = np.array(Ains)\n",
    "\n",
    "    if Ain_min:\n",
    "        mask=np.array(Ains>=Ain_min)\n",
    "        bbs=bbs[mask]\n",
    "        points=points[mask]\n",
    "        Ains=Ains[mask]\n",
    "        if len(bbs)==0:\n",
    "            return [],[],[],[]           \n",
    "    \n",
    "    scores = bbs[:,-1]\n",
    "    bbs = bbs[:, :4]\n",
    "    \n",
    "    return points, bbs, scores, Ains\n",
    "\n",
    "def retinaface(image):\n",
    "\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    \n",
    "    image_pad, pad_params = pad_input_image(image)    \n",
    "    image_pad = tf.convert_to_tensor(image_pad[np.newaxis, ...])\n",
    "    image_pad = tf.cast(image_pad, tf.float32)  \n",
    "   \n",
    "    outputs = detector_model(image_pad).numpy()\n",
    "\n",
    "    outputs = recover_pad_output(outputs, pad_params)\n",
    "    Nfaces = len(outputs)\n",
    "    \n",
    "    bbs = np.zeros((Nfaces,5))\n",
    "    lms = np.zeros((Nfaces,10))\n",
    "    \n",
    "    bbs[:,[0,2]] = outputs[:,[0,2]]*width\n",
    "    bbs[:,[1,3]] = outputs[:,[1,3]]*height\n",
    "    bbs[:,4] = outputs[:,-1]\n",
    "    \n",
    "    lms[:,0:5] = outputs[:,[4,6,8,10,12]]*width\n",
    "    lms[:,5:10] = outputs[:,[5,7,9,11,13]]*height\n",
    "    \n",
    "    return bbs, lms\n",
    "\n",
    "def pad_input_image(img, max_steps=32):\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    img_pad_h = 0\n",
    "    if img_h % max_steps > 0:\n",
    "        img_pad_h = max_steps - img_h % max_steps\n",
    "\n",
    "    img_pad_w = 0\n",
    "    if img_w % max_steps > 0:\n",
    "        img_pad_w = max_steps - img_w % max_steps\n",
    "\n",
    "    padd_val = np.mean(img, axis=(0, 1)).astype(np.uint8)\n",
    "    img = cv2.copyMakeBorder(img, 0, img_pad_h, 0, img_pad_w,\n",
    "                             cv2.BORDER_CONSTANT, value=padd_val.tolist())\n",
    "    pad_params = (img_h, img_w, img_pad_h, img_pad_w)\n",
    "\n",
    "    return img, pad_params\n",
    "\n",
    "def recover_pad_output(outputs, pad_params):\n",
    "    img_h, img_w, img_pad_h, img_pad_w = pad_params\n",
    "    recover_xy = np.reshape(outputs[:, :14], [-1, 7, 2]) * \\\n",
    "        [(img_pad_w + img_w) / img_w, (img_pad_h + img_h) / img_h]\n",
    "    outputs[:, :14] = np.reshape(recover_xy, [-1, 14])\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e80fb8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "camera resolution: [[480 640]]\n"
     ]
    }
   ],
   "source": [
    "# FONT SETTING (font style, size and color)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX # Text in video\n",
    "font_size = 0.4\n",
    "blue = (225,0,0)\n",
    "green = (0,120,0)\n",
    "red = (0,0,255)\n",
    "orange = (0,140,255)\n",
    "\n",
    "# DEMO GUI SETTING\n",
    "total_size = np.array([750, 1400], dtype=int) # demo-gui size (resolution)\n",
    "# complete/final frame to be shown on demo-gui\n",
    "frame_show = np.ones((total_size[0], total_size[1], 3), dtype='uint8')*255 \n",
    "logo_size = 150\n",
    "show_size = 150 # Size showed detected faces\n",
    "res_max = np.zeros((2), dtype=int)\n",
    "res_resize = np.zeros((2), dtype=int)\n",
    "\n",
    "# CAMERA SETTING\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "res_actual = np.zeros((1,2), dtype=int)# actual resolution of the camera\n",
    "res_actual[0,0] = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "res_actual[0,1] = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "print(\"\\ncamera resolution: {}\".format(res_actual))\n",
    "\n",
    "# PROCESS FRAMES\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    if not (ret):\n",
    "        break\n",
    "    #print(ret)\n",
    "    \n",
    "    frame = np.array(frame)\n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    res_crop = np.asarray(frame.shape)[0:2]\n",
    "           \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    pointss_all, bbs_all, scores_all, _ = face_detector(frame_rgb, image_shape_max=640, score_min=0.95,\n",
    "                                                        pixel_min=20, pixel_max=1000, Ain_min=90)\n",
    "\n",
    "    if len(bbs_all) > 0:# if at least one face is detected\n",
    "        bbs_all = np.insert(bbs_all,bbs_all.shape[1],scores_all,axis=1)\n",
    "        pointss_all = np.transpose(pointss_all)\n",
    "\n",
    "        bbs = bbs_all.copy()\n",
    "        pointss = pointss_all.copy()\n",
    "        \n",
    "        #process only one face (center ?)  \n",
    "        bb,points = one_face(frame, bbs, pointss)\n",
    "        \n",
    "        draw_landmarks(frame, bb, points)# draw land marks on face   \n",
    "        \n",
    "        cv2.putText(frame, \"Roll: {0:.2f} (- : left spin / + : right spin)\".format(find_roll(points)), (10,90), font, font_size, red, 1)  \n",
    "        cv2.putText(frame, \"Yaw: {0:.2f} (- : left / + : right)\".format(find_yaw(points)), (10,100), font, font_size, red, 1)\n",
    "        cv2.putText(frame, \"Pitch: {0:.2f} (0 : up / 4 : down)\".format(find_pitch(points)), (10,110), font, font_size, red, 1)\n",
    "        \n",
    "        # 좌 우\n",
    "        if find_yaw(points) < -20 and find_pitch(points) > 0.5 and find_pitch(points) < 1.5 and find_roll(points) > -15 and find_roll(points) < 15:\n",
    "            label = \"left\"\n",
    "        elif find_yaw(points) > 20 and find_pitch(points) > 0.5 and find_pitch(points) < 1.5 and find_roll(points) > -15 and find_roll(points) < 15:\n",
    "            label = \"right\"\n",
    "                \n",
    "        # 위 아래\n",
    "        elif find_yaw(points) > -20 and find_yaw(points) < 20 and find_pitch(points) < 0.5 and find_roll(points) > -8 and find_roll(points) < 8:\n",
    "            label = \"up\"\n",
    "        elif find_yaw(points) > -20 and find_yaw(points) < 20 and find_pitch(points) > 1.5 and find_roll(points) > -5 and find_roll(points) < 5:\n",
    "            label = \"down\"\n",
    "            \n",
    "        # 좌 우 대각선 위\n",
    "        elif find_yaw(points) < -20 and find_pitch(points) < 0.5: label = \"left up\"\n",
    "        elif find_yaw(points) > 20 and find_pitch(points) < 0.5: label = \"right up\"\n",
    "            \n",
    "        # 좌 우 대각선 아래\n",
    "        elif find_yaw(points) < -10 and find_pitch(points) > 1.5: label = \"left down\"\n",
    "        elif find_yaw(points) > 10 and find_pitch(points) > 1.5: label = \"right down\"\n",
    "        \n",
    "        # 정면\n",
    "        else: label = \"forward\"\n",
    "        \n",
    "        cv2.putText(frame, label, (10,140), font, 0.7, green, 1)\n",
    "        \n",
    "        # x, y 축\n",
    "        cv2.line(frame, (0, 250), (640, 250), 3)\n",
    "        cv2.line(frame, (320, 0), (320, 480), 3)\n",
    "\n",
    "        #Xfrontal, Yfrontal = find_pose(points)\n",
    "        #cv2.putText(frame, \"Xfrontal: {0:.2f}\".format(Xfrontal), (10,130), font, font_size, red, 1)\n",
    "        #cv2.putText(frame, \"Yfrontal: {0:.2f}\".format(Yfrontal), (10,140), font, font_size, red, 1)\n",
    "    \n",
    "    #else:\n",
    "    #    cv2.putText(frame_show, 'No face', (10,logo_size+200), font, font_size, blue, 2)\n",
    "                \n",
    "    res_max[0]=total_size[0]#-show_size\n",
    "    res_max[1]=total_size[1]-2*logo_size\n",
    "    \n",
    "    res_resize[1]=res_max[1]\n",
    "    res_resize[0]=res_max[1]/res_crop[1]*res_crop[0]\n",
    "\n",
    "    if  res_resize[0]>res_max[0]:\n",
    "        res_resize[0]=res_max[0]\n",
    "        res_resize[1]=int(res_max[0]/res_crop[0]*res_crop[1]/2)*2\n",
    "\n",
    "    frame_resize = cv2.resize(frame,(res_resize[1],res_resize[0]), interpolation = cv2.INTER_LINEAR)    \n",
    "    space_vert=(total_size[1]-res_resize[1]) // 2 \n",
    "\n",
    "    frame_show[:frame_resize.shape[0],space_vert:-space_vert,:]=frame_resize \n",
    "    \n",
    "    cv2.putText(frame_show, 'q: quit', (10,50), font, font_size, blue, 2)    \n",
    "    cv2.imshow('Head Pose Estimation - Retina Face',frame_show)    \n",
    "    \n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    option=[]\n",
    "    options=['Quit']\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7dbe7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
